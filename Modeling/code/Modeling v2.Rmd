---
title: "Exploration"
output: html_document
---

## read data

```{r}

library(ggplot2)
library(tidyverse)
library(dplyr)
library(rgdal)
library(rgeos)
library(raster)
library(sf)
library(sp)
library(tmap)
library(viridis)
library(spdep)
library(spatialreg)

#E:/R-code/Modeling/code/FCN_clean_csvs.R
#~/Documents/R-code
source('E:/R-code/Modeling/code/FCN_clean_csvs.R')

median_cell_raw <- read.csv('E:/R-code/Modeling/data/median_onset_cell_v2.csv')
percentile5_cell_raw <- read.csv('E:/R-code/Modeling/data/percentile5_onset_cell_v2.csv')
percentile95_cell_raw <- read.csv('E:/R-code/Modeling/data/percentile95_onset_cell_v2.csv')

median_muni_raw <- read.csv('E:/R-code/Modeling/data/median_muni_v2.csv')
percentile5_muni_raw <- read.csv('E:/R-code/Modeling/data/percentile5_muni_v2.csv')
percentile95_muni_raw <- read.csv('E:/R-code/Modeling/data/percentile95_muni_v2.csv')

median_CARpoly_raw <- read.csv('E:/R-code/Modeling/data/median_CARpoly_v2.csv')
percentile5_CARpoly_raw <- read.csv('E:/R-code/Modeling/data/percentile5_CARpoly_v2.csv')
percentile95_CARpoly_raw <- read.csv('E:/R-code/Modeling/data/percentile95_CARpoly_v2.csv')

grid_1deg <- readOGR(dsn = 'E:/R-code/Modeling/data/shp/grid_1deg', layer = 'grid_1deg')
munis <- readOGR(dsn = 'E:/R-code/Modeling/data/shp/munis', layer = 'munis_SHP')
crs(munis) <- CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0")
  
#cell_shp <- readOGR(dsn = 'E:/R-code/Modeling/data/shp/median_onset_cell', layer = 'median_onset_cell_SHP')


```

## read and clean spatial data

```{r}

cell_sf <- st_read(dsn = 'E:/R-code/Modeling/data/shp/median_onset_cell', layer = 'median_onset_cell_SHP')

cell_sf_tidy <- cell_sf %>% tidy_by_intensity_plant("SC_plant", "DC_plant") %>%
            tidy_by_intensity_delay("SC_delay", "DC_delay") %>%
            dplyr::select(-c(SC_harvest, DC_harvest))
cell_sf_tidy$year_index <- cell_sf_tidy$year - 2003

```

## spatial join muni to CARpolys

```{r}

# rename columns of CARpoly data and combine into a single csv before spatial join
median_CARpoly_raw <- rename_cols_median_CARpoly(median_CARpoly_raw)
percentile5_CARpoly_raw <- rename_cols_percentile5_CARpoly(percentile5_CARpoly_raw)
percentile95_CARpoly_raw <- rename_cols_percentile95_CARpoly(percentile95_CARpoly_raw)
CARpoly_raw <- create_CARpoly_raw(median_CARpoly_raw, percentile5_CARpoly_raw, percentile95_CARpoly_raw)

CARpoly_raw <- join_CARpoly_to_muni(CARpoly_raw)

```

## constants

```{r}

min_soy_area <- 2 #km2. min area of total or SC/DC soy in cell, muni or property to be considered in model

```

## rename and delete the columns (only needed for median)

```{r}

# median cell
median_cell <- median_cell_raw %>% delete_cols_median_cell() %>%
                                    rename_cols_median_cell()
percentile5_cell <- percentile5_cell_raw %>% filter(year > 0)
percentile95_cell <- percentile95_cell_raw %>% filter(year > 0)

# median muni
median_muni <- median_muni_raw %>% rename_cols_median_muni()
percentile5_muni <- percentile5_muni_raw %>% filter(year > 0)
percentile95_muni <- percentile95_muni_raw %>% filter(year > 0)

```


## tidy the data and categorize the numeric variables

```{r}

# create tidy datasets
cell_tidy <- tidy_combine_cell(median_cell, percentile5_cell, percentile95_cell)
muni_tidy <- tidy_combine_muni(median_muni, percentile5_muni, percentile95_muni)
CARpoly_tidy <- tidy_CARpoly(CARpoly_raw)



# categorize numeric variables
cell_tidy <- categorize_vars_cell_tidy(cell_tidy)
cell_untidy <- categorize_vars_cell_untidy(median_cell)

muni_tidy <- categorize_vars_muni_tidy(muni_tidy)
muni_untidy <- categorize_vars_muni_untidy(median_muni)


CARpoly_tidy <- categorize_vars_CARpoly_tidy(CARpoly_tidy) %>% delete_cols_CARpoly_tidy()
CARpoly_untidy <- categorize_vars_CARpoly_untidy(CARpoly_raw) 
# change rename cols and delete unnecessary cols
CARpoly_untidy <- CARpoly_untidy %>% rename_cols_CARpoly_untidy() %>%
                                    delete_cols_CARpoly_untidy()
  

# categorize as new or old or neither in planted soy age (so far only have it for cell scale)
cell_tidy <- cell_tidy %>% cell_categorize_soy_age()
cell_untidy <- cell_untidy %>% cell_categorize_soy_age()

# add year_index and year_factor
cell_tidy$year_index <- cell_tidy$year - 2003
cell_untidy$year_index <- cell_untidy$year - 2003
muni_tidy$year_index <- muni_tidy$year - 2003
muni_untidy$year_index <- muni_untidy$year - 2003
CARpoly_tidy$year_index <- CARpoly_tidy$year - 2003
CARpoly_untidy$year_index <- CARpoly_untidy$year - 2003

cell_tidy$year_factor <- cell_tidy$year %>% as.factor()
cell_untidy$year_factor <- cell_untidy$year %>% as.factor()
muni_tidy$year_factor <- muni_tidy$year %>% as.factor()
muni_untidy$year_factor <- muni_untidy$year %>% as.factor()
CARpoly_tidy$year_factor <- CARpoly_tidy$year %>% as.factor()
CARpoly_untidy$year_factor <- CARpoly_untidy$year %>% as.factor()

# use muni_code as factor
cell_tidy$Muni_code_factor <- cell_tidy$Muni_code %>% as.factor()
cell_untidy$Muni_code_factor <- cell_untidy$Muni_code %>% as.factor()
CARpoly_tidy$Muni_code_factor <- CARpoly_tidy$Muni_code %>% as.factor()
CARpoly_untidy$Muni_code_factor <- CARpoly_untidy$Muni_code %>% as.factor()

# choose munis that were planted in 2014 and 2004, merge them 
#munis_2014 <- muni_tidy[muni_tidy$year == "2014", c("total_planted_area_km2", "Muni_code")]
#munis_2004 <- muni_tidy[muni_tidy$Muni_code %in% munis_2014$Muni_code & 
#                          muni_tidy$year == "2004", c("total_planted_area_km2", "Muni_code")]
#munis_2014 <- munis_2014 %>% rename(area_2014 = total_planted_area_km2)
#munis_2004 <- munis_2004 %>% rename(area_2004 = total_planted_area_km2)
#munis_merged <- merge(munis_2014, munis_2004, by = "Muni_code") %>% unique()
#soy_age <- rep("neither", length(munis_merged$Muni_code))
```

## modeling functions

```{r}

# list of numeric x variable names, to be used in multicollinearity test
numeric.x.var.names <- c("onset", "latitude", "longitude", "onset_historicalRange", "year", "year_index")

# do linear model
# NEEDS year fixed effect, spatial fixed effect, FE vs ME, spatial autocorrelation handling
do_lm <- function(data, y.var,  spatial.auto.model, x.vars,
                  crop.intensity, mask.soy.area) {
  # options:
  # x.vars = vector of predictors, names of variables are in quotes, and interactions as will be written in the lm formula, e.g. onset:latitude
  # crop.intensity = "none", "DC", "SC"
  # spatial.fe.scale = "none", "regions.4", "municipality", "grid.1deg", "geo.weighted"
  # spatial.auto.model = "none", "spatial.lag", "spatial.error"
  # interaction.pairs = 
  # mask.soy.area = TRUE or FALSE, if TRUE take out rows with total soy area below min_soy_area
  
  # subset the data  --------------------------------------------------------------------------------------------------------
  # get only the desired cropping intensity
  data.subset <- if(crop.intensity == "none") {
    data
  } else {
    data[data$intensity == crop.intensity,]
  }
  
  # get rid of observations with low soy area
  data.subset <- if(mask.soy.area) {
    data.subset[data.subset$total_planted_area_km2 >= min_soy_area,]
  }
  
  # define the formula ------------------------------------------------------------------------------------------------------
  # define the basic formula
  formula.string <- paste(y.var, paste(x.vars, collapse = " + "), sep = " ~ ")
  
  f <- as.formula(formula.string)

  # do the model -------------------------------------------------------------------------------------------------------------
  # evaluate model. note, simpler alternative: model <- lm(f, data = data.subset)
  model <- eval(bquote(   lm(.(f), data = data.subset)   ))
  
  return(model)
}


# given an initial model, step through potential new predictors and pick the best one. 
add_predictor_stepwise <- function(data, initial.predictors, y.var, spatial.auto.model,
                                   new.predictors, crop.intensity, mask.soy.area) {
  
  # given an initial set of predictors, add another one based on adj R2
  # notes:
  # the data determines the observation scale
  # interactions to explore are in new.predictors
  # spatial FE scale is determined in the initial.predictors and interaction terms
  
  # calculate adj R2 of initial model
  initial_model <- do_lm(data = data, 
              y.var = y.var, 
              x.vars = initial.predictors, 
              spatial.auto.model = spatial.auto.model,  
              crop.intensity = crop.intensity,
              mask.soy.area = mask.soy.area)
  
  initial_adjR2 <- summary(initial_model)$adj.r.squared
  
  # initialize 'best' new predictor and best adj_R2
  best_new_predictor <- "none"
  current_best_adjR2 <- initial_adjR2
  
  # initialize vector to store adj R2
  new_adjR2s <- c(initial_adjR2)
  
  # loop through potential new predictors
  for (predictor in new.predictors) {
    
    # calculate new adjR2 and save it
    new_model <- do_lm(data = data, 
              y.var = y.var, 
              x.vars = c(initial.predictors, predictor), 
              spatial.auto.model = spatial.auto.model,  
              crop.intensity = crop.intensity,
              mask.soy.area = mask.soy.area)
    
    new_adjR2 <- summary(new_model)$adj.r.squared
    new_adjR2s <- c(new_adjR2s, new_adjR2)
    
    # if new_adjR2 is better, update the new_best_predictor
    if (new_adjR2 > current_best_adjR2) {
      current_best_adjR2 <- new_adjR2
      best_new_predictor <- predictor
    }
  }
  
  # return best predictor, its adjR2, and the list of other predictors' R2
  all_adjR2 <- data.frame(model = c("initial", new.predictors), adjR2 = new_adjR2s)
  
  return(list(new_predictor = best_new_predictor, 
              new_adjR2 = current_best_adjR2,  
              adjR2_table = all_adjR2))
}

# runs add_predictor_stepwise to build the final model
produce_model_stepwise <- function(data, initial.predictors, y.var, spatial.auto.model,
                                   new.predictors, crop.intensity, mask.soy.area, max.predictors) {
  # notes
  # max.predictors = the max allowed number of predictors in the model
  
  model_finalized <- FALSE
  iterations <- 0
  
  while (!model_finalized & iterations <= 10) {
    
    iterations <- iterations + 1
    
    # add a new predictor, save results
    result <- add_predictor_stepwise(data, initial.predictors, y.var, spatial.auto.model,
                       new.predictors, crop.intensity, mask.soy.area)
    
    new_predictor <- result$new_predictor
    new_adjR2_table <- result$adjR2_table
    new_adjR2 <- result$new_adjR2

    print(new_adjR2_table)
    
    # check if the model returned 'none' or the max.predictors was reached; if so, model is finalized
    # if model is finalized, return the model
    if (new_predictor == "none" | length(initial.predictors) >= max.predictors) { 
      model_finalized <- TRUE
      
      final_predictors <- initial.predictors
      final_adjR2 <- new_adjR2
      
      # run the final model to return the lm output
      final_model <- do_lm(data = data, 
              y.var = y.var, 
              x.vars = final_predictors, 
              spatial.auto.model = spatial.auto.model,  
              crop.intensity = crop.intensity,
              mask.soy.area = mask.soy.area)
      
    }
    
    # if model isn't done adding predictors, update initial.predictors for the new iteration
    initial.predictors <- c(initial.predictors, new_predictor)
    
  }
  
  # return
  return(list(final_model = final_model,
              final_predictors = final_predictors,
              final_adjR2 = final_adjR2))
}

evaluate_model <- function(lm_results, test.x.vars, orig_data, title) {
  
  print(title)
  print(summary(lm_results))
  plot(lm_results, which = c(1,2), main = title) # test error is homoscedastic, zero mean, normal
  
  # test pearson's correlation for numeric variables used
  df <- orig_data %>% subset(select = test.x.vars[test.x.vars %in% numeric.x.var.names])
  test.corr <- cor(df)
  
  print(c('predictor correlation matrix', title))
  print(test.corr)
}




```

## building a model stepwise automated

```{r}
# remove variables
rm(data)
rm(initial.predictors)
rm(y.var)
rm(spatial.auto.model)
rm(new.predictors)
rm(crop.intensity)
rm(mask.soy.area)

# test produce_model_stepwise
data <- muni_tidy
initial.predictors <- c("onset", "intensity")
y.var <- "plant_median"
spatial.auto.model <- "none"
new.predictors <- c("latitude", "longitude", "region", # for spatial effects
                     "year_factor", # for time effects
                    "onset_historicalRange",  # other predictors
                    "onset:latitude", "onset:longitude", "onset:region", # interactions: for spatial effects
                    "onset:year_factor", # interactions: for time effects
                    "onset:intensity") # interactions: other predictors
crop.intensity <- "none"
mask.soy.area <- TRUE


model <- produce_model_stepwise(data, initial.predictors, y.var, spatial.auto.model,
                       new.predictors, crop.intensity, mask.soy.area, 6)
evaluate_model(model$final_model, model$final_predictors, data, "output from produce_model_stepwise")


```

## spatial studies: first, check residual autocorrelation in basic OLS

```{r}
# do basic OLS model and see if residuals are autocorrelated ----------------------------

cell_sf_tidy <- cell_sf_tidy %>%  drop_na

model_ols <- lm(plant ~ onset + intensity + lat + year_index + onset:intensity, data=cell_sf_tidy)
summary(model_ols)

cell_sf_tidy$residuals <- residuals(model_ols)

#ggplot(cell_sf_tidy) +
#  geom_sf(aes(fill = residuals)) +
#  scale_fill_viridis() +
#  ggtitle("Residuals for basic OLS") +
#  theme_bw()


# see if basic OLS residuals are autocorrelated with scatterplot -------------------------

nb <- poly2nb(cell_sf_tidy)
resnb <- sapply(nb, function(x) mean(cell_sf_tidy$residuals[x]))
cor(cell_sf_tidy$residuals, resnb)
plot(cell_sf_tidy$residuals, resnb, xlab='Residuals', ylab='Mean adjacent residuals', main = "Basic OLS, all years")
lw <- nb2listw(nb, zero.policy = TRUE)
moran_basic_ols <- moran.mc(cell_sf_tidy$residuals, lw, 999, zero.policy = TRUE)
print('moran with basic ols, all years')
print(moran_basic_ols)

```

## spatial studies: check residual autocorrelation in basic OLS for one year

```{r}
# test basic OLS for one year only (to be compared to spatial lag and spatial error) ----------------------------
year_oi <- 2013

# filter a specific year
cell_sf_tidy_year <- cell_sf_tidy %>% filter(year == year_oi)
model_ols <- lm(plant ~ onset + intensity + lat + onset:intensity, data=cell_sf_tidy_year)
summary(model_ols)

cell_sf_tidy_year$residuals <- residuals(model_ols)

ggplot(cell_sf_tidy_year) +
  geom_sf(aes(fill = residuals)) +
  scale_fill_viridis() +
  ggtitle(paste("Residuals for basic OLS,", year_oi)) +
  theme_bw()

nb <- poly2nb(cell_sf_tidy_year)
resnb <- sapply(nb, function(x) mean(cell_sf_tidy_year$residuals[x]))
plot(cell_sf_tidy_year$residuals, resnb, xlab='Residuals', ylab='Mean adjacent residuals', main = paste("Basic OLS,", year_oi))
lw <- nb2listw(nb, zero.policy = TRUE)
moran_basic_ols <- moran.mc(cell_sf_tidy_year$residuals, lw, 999, zero.policy = TRUE)
print('moran with basic ols, one year')
print(moran_basic_ols)

```

## spatial studies: second, fit spatial lag and error models
source: https://rspatial.org/analysis/7-spregression.html

```{r}
year_oi <- 2013

cell_sf_tidy <- cell_sf_tidy %>%  drop_na

# filter a specific year
cell_sf_tidy_year <- cell_sf_tidy %>% filter(year == year_oi)

nb <- poly2nb(cell_sf_tidy_year)
lw <- nb2listw(nb, zero.policy = TRUE)

# spatial lag model ---------------------------------------------------------------------
model_lag = lagsarlm(plant ~ onset + intensity + lat + onset:intensity, data=cell_sf_tidy_year, lw, tol.solve=1.0e-30,
                     zero.policy = TRUE)
summary(model_lag)

cell_sf_tidy_year$residuals_lag <- residuals(model_lag)

nb <- poly2nb(cell_sf_tidy_year)
resnb <- sapply(nb, function(x) mean(cell_sf_tidy_year$residuals_lag[x]))
cor(cell_sf_tidy_year$residuals, resnb)
plot(cell_sf_tidy_year$residuals, resnb, xlab='Residuals', ylab='Mean adjacent residuals', main = paste("Spatial lag,", year_oi))
lw <- nb2listw(nb, zero.policy = TRUE)
moran_basic_ols <- moran.mc(cell_sf_tidy_year$residuals, lw, 999, zero.policy = TRUE)

ggplot(cell_sf_tidy_year) +
  geom_sf(aes(fill = residuals_lag)) +
  scale_fill_viridis() +
  ggtitle(paste("Residuals for spatial lag model,", year_oi)) +
  theme_bw()

# spatial error model ---------------------------------------------------------------------
model_error = errorsarlm(plant ~ onset + intensity + lat + onset:intensity, data=cell_sf_tidy_year, lw, tol.solve=1.0e-30,
                     zero.policy = TRUE)
summary(model_error)

cell_sf_tidy_year$residuals_error <- residuals(model_error)

nb <- poly2nb(cell_sf_tidy_year)
resnb <- sapply(nb, function(x) mean(cell_sf_tidy_year$residuals_error[x]))
cor(cell_sf_tidy_year$residuals_error, resnb)
plot(cell_sf_tidy_year$residuals_error, resnb, xlab='Residuals', ylab='Mean adjacent residuals', main = paste("Spatial error,", year_oi))
lw <- nb2listw(nb, zero.policy = TRUE)
moran_basic_ols <- moran.mc(cell_sf_tidy_year$residuals_error, lw, 999, zero.policy = TRUE)

ggplot(cell_sf_tidy_year) +
  geom_sf(aes(fill = residuals_error)) +
  scale_fill_viridis() +
  ggtitle(paste("Residuals for spatial error model,", year_oi)) +
  theme_bw()

```


## spatial studies: spatially weighted regression
source: 
http://www.spatialanalysisonline.com/An%20Introduction%20to%20Spatial%20Data%20Analysis%20in%20R.pdf

```{r}
library(spgwr) # spatially weighted regression

year_oi <- 2013

# filter for a specific year, then turn sf object into SPDF
cell_sf_tidy <- cell_sf_tidy %>%  drop_na
cell_sf_tidy_year <- cell_sf_tidy %>% filter(year == year_oi)
cell_spdf_tidy_year <- as(cell_sf_tidy_year, 'Spatial')

#run GWR
#calculate kernel bandwidth (takes a long time)
GWRbandwidth <- gwr.sel(plant ~ onset + intensity + lat + onset:intensity, 
data = cell_spdf_tidy_year, adapt =TRUE)

#run the gwr model
gwr.model <- gwr(plant ~ onset + intensity + lat + onset:intensity, 
                        data = cell_spdf_tidy_year, adapt=GWRbandwidth, hatmatrix=TRUE, se.fit=TRUE)
#print the results of the model
gwr.model

# third, map the results 
# HOW TO SELECT ONLY CERTAIN YEARS??? DO MODEL FOR SELECT YEAR?
results <-as.data.frame(gwr.model$SDF)
gwr.map <- cbind(cell_tidy, as.matrix(results))

# create tmap objects
map1 <- tm_shape(gwr.map) + 
  tm_fill("localR2", n = 5, style = "quantile", title = "Local R2") +
  tm_layout(frame = FALSE, legend.text.size = 0.5, legend.title.size = 0.6)
map2 <- tm_shape(gwr.map) + tm_fill("cell_tidy.onset", n = 5, style = "quantile",
title = "Onset Coefficient") +
tm_layout(frame = FALSE, legend.text.size = 0.5, legend.title.size = 0.6)
map3 <- tm_shape(gwr.map) + tm_fill("Cell_tidy.intensity", n = 5, style = "quantile",
title = "Intensity Coefficient") +
tm_layout(frame = FALSE, legend.text.size = 0.5, legend.title.size = 0.6)
map4 <- tm_shape(gwr.map) + tm_fill("cell_tidy.year_index", n = 5, style = "quantile",
title = "Year Coefficient") +
tm_layout(frame = FALSE, legend.text.size = 0.5, legend.title.size = 0.6)

library(grid)
library(gridExtra)
# creates a clear grid
grid.newpage()
# assigns the cell size of the grid, in this case 2 by 2
pushViewport(viewport(layout=grid.layout(2,2)))
# prints a map object into a defined cell
print(map1, vp=viewport(layout.pos.col = 1, layout.pos.row =1))
print(map2, vp=viewport(layout.pos.col = 2, layout.pos.row =1))
print(map3, vp=viewport(layout.pos.col = 1, layout.pos.row =2))
print(map4, vp=viewport(layout.pos.col = 2, layout.pos.row =2))
```





## spatially weighted regression, try 2
source: https://rspatial.org/analysis/6-local_regression.html

```{r}

# compute a model for grid cells


r <- raster(MT_boundary)
res(r) <- 50000 # 50km
xy <- xyFromCell(r, 1:ncell(r))

#For each cell, we need to select a number of observations, let’s say within 50 km of the center of each cell (thus the data that are used in different cells overlap). And let’s require at least 50 observations to do a regression.

crds <- coordinates(cell_tidy)

regfun2 <- function(d)  {
 m <- glm(plant_median ~ onset, intensity, latitude, year_index, 
                        latitude, onset:soy_age, onset:intensity, 
                        data = cell_tidy)
 coefficients(m)
}

#Run the model for al cells if there are at least 50 observations within a radius of 50 km.

res <- list()
for (i in 1:nrow(xy)) {
    d <- sqrt((xy[i,1]-crds[,1])^2 + (xy[i,2]-crds[,2])^2)
    j <- which(d < 50000)
    if (length(j) > 49) {
        d <- hd[j,]
        res[[i]] <- regfun2(d)
    } else {
        res[[i]] <- NA
    }
}

#For each cell get the onset coefficient:

inc <- sapply(res, function(x) x['onset'])

#Use these values in a RasterLayer

rinc <- setValues(r, inc)
plot(rinc)
plot(cell_tidy, add=T)

Moran(rinc)
```

## spatially weighted regression, try 3
source: https://rspatial.org/analysis/6-local_regression.html

```{r}
#Create a RasterLayer with the correct extent

r <- raster(cell_tidy)

#Set to a desired resolution. I choose 25 km

res(r) <- 25000

#I only want cells inside of CA, so I add some more steps.

ca <- rasterize(cell_tidy, r)
#Extract the coordinates that are not NA.

fitpoints <- rasterToPoints(ca)

# specify the model as gwr.model

sp <- gwr.model$SDF
spplot(sp)
cells <- cellFromXY(r, fitpoints)
dd <- as.matrix(data.frame(sp))
b <- brick(r, values=FALSE, nl=ncol(dd))
b[cells] <- dd
names(b) <- colnames(dd)
plot(b)


```